{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Who are the top 5 users in Chicago with the highest number of followers? List their login in order, comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cassidoo,felangel,dabeaz,sstephenson,mattgodbolt\n"
     ]
    }
   ],
   "source": [
    "users = []\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\users.csv'\n",
    "\n",
    "# Read the CSV file with UTF-8 encoding\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        location = row['location'].strip().lower()\n",
    "        # Check if the user is from Delhi\n",
    "        if 'chicago' in location:\n",
    "            users.append({\n",
    "                'login': row['login'],\n",
    "                'followers': int(row['followers'])\n",
    "            })\n",
    "\n",
    "# Sort users based on followers in descending order\n",
    "top_users = sorted(users, key=lambda x: x['followers'], reverse=True)\n",
    "\n",
    "# Extract the top 5 user logins\n",
    "top_5_logins = [user['login'] for user in top_users[:5]]\n",
    "\n",
    "# Print the result as a comma-separated list\n",
    "print(','.join(top_5_logins))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Who are the 5 earliest registered GitHub users in Chicago? List their login in ascending order of created_at, comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELLIOTTCABLE,trevorturk,lukehoersten,djspiewak,shanesveller\n"
     ]
    }
   ],
   "source": [
    "users = []\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\users.csv'\n",
    "\n",
    "# Read the CSV file with UTF-8 encoding\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        location = row['location'].strip().lower()\n",
    "        # Check if the user is from Delhi\n",
    "        if 'chicago' in location:\n",
    "            users.append({\n",
    "                'login': row['login'],\n",
    "                'created_at': datetime.strptime(row['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "            })\n",
    "\n",
    "# Sort users based on created_at in ascending order\n",
    "sorted_users = sorted(users, key=lambda x: x['created_at'])\n",
    "\n",
    "# Extract the top 5 user logins\n",
    "top_5_earliest_logins = [user['login'] for user in sorted_users[:5]]\n",
    "\n",
    "# Print the result as a comma-separated list\n",
    "print(','.join(top_5_earliest_logins))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What are the 3 most popular license among these users? Ignore missing licenses. List the license_name in order, comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mit,other,apache-2.0\n"
     ]
    }
   ],
   "source": [
    "# Define the list to store license names\n",
    "licenses = []\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\repositories.csv'\n",
    "\n",
    "# Read the CSV file with UTF-8 encoding\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        # Check if the license_name field is present and not empty\n",
    "        license_name = row.get('license_name', '').strip()\n",
    "        if license_name:\n",
    "            licenses.append(license_name)\n",
    "\n",
    "# Count the occurrence of each license\n",
    "license_counts = Counter(licenses)\n",
    "\n",
    "# Get the 3 most common licenses\n",
    "top_3_licenses = [license for license, count in license_counts.most_common(3)]\n",
    "\n",
    "# Print the result as a comma-separated list\n",
    "print(','.join(top_3_licenses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Which company do the majority of these developers work at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIVERSITY OF CHICAGO\n"
     ]
    }
   ],
   "source": [
    "# Define the list to store company names\n",
    "companies = []\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\users.csv'\n",
    "\n",
    "# Read the CSV file with UTF-8 encoding\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        # Get and clean up the company field (ignore empty values)\n",
    "        company = row.get('company', '').strip()\n",
    "        if company:\n",
    "            companies.append(company)\n",
    "\n",
    "# Count the occurrence of each company\n",
    "company_counts = Counter(companies)\n",
    "\n",
    "# Find the most common company\n",
    "most_common_company = company_counts.most_common(1)\n",
    "\n",
    "# Print the result\n",
    "if most_common_company:\n",
    "    print(most_common_company[0][0])\n",
    "else:\n",
    "    print(\"No company data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which programming language is most popular among these users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript\n"
     ]
    }
   ],
   "source": [
    "# Define the list to store programming languages\n",
    "languages = []\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\repositories.csv'\n",
    "\n",
    "# Read the CSV file with UTF-8 encoding\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        # Get and clean up the language field (ignore empty values)\n",
    "        language = row.get('language', '').strip()\n",
    "        if language:\n",
    "            languages.append(language)\n",
    "\n",
    "# Count the occurrence of each language\n",
    "language_counts = Counter(languages)\n",
    "\n",
    "# Find the most common language\n",
    "most_common_language = language_counts.most_common(1)\n",
    "\n",
    "# Print the result\n",
    "if most_common_language:\n",
    "    print(most_common_language[0][0])\n",
    "else:\n",
    "    print(\"No language data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which programming language is the second most popular among users who joined after 2020?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript\n"
     ]
    }
   ],
   "source": [
    "# Define the list to store programming languages\n",
    "languages = []\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\repositories.csv'\n",
    "\n",
    "# Read the CSV file with UTF-8 encoding\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    # Iterate through the rows in the CSV\n",
    "    for row in reader:\n",
    "        # Parse the created_at field\n",
    "        created_at = row.get('created_at', '').strip()\n",
    "        \n",
    "        # Convert the date string to a datetime object\n",
    "        if created_at:\n",
    "            user_join_date = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            \n",
    "            # Check if the user joined after 2020\n",
    "            if user_join_date.year > 2020:\n",
    "                # Get the language field and clean it up\n",
    "                language = row.get('language', '').strip()\n",
    "                if language:\n",
    "                    languages.append(language)\n",
    "\n",
    "# Count the occurrence of each language\n",
    "language_counts = Counter(languages)\n",
    "\n",
    "# Find the two most common languages\n",
    "most_common_languages = language_counts.most_common(2)\n",
    "\n",
    "# Print the second most common language\n",
    "if len(most_common_languages) >= 2:\n",
    "    print(most_common_languages[1][0])  # Second most common language\n",
    "else:\n",
    "    print(\"Not enough language data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Which language has the highest average number of stars per repository?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vim Script\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary to store total stars and repository count per language\n",
    "language_stats = defaultdict(lambda: {'stars': 0, 'repos': 0})\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\repositories.csv'\n",
    "\n",
    "# Read the CSV file with UTF-8 encoding\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        # Get the language and stargazers_count field\n",
    "        language = row.get('language', '').strip()\n",
    "        stars = row.get('stargazers_count', '0').strip()\n",
    "\n",
    "        # Only process if language and stars are available\n",
    "        if language and stars.isdigit():\n",
    "            language_stats[language]['stars'] += int(stars)\n",
    "            language_stats[language]['repos'] += 1\n",
    "\n",
    "# Calculate average stars for each language\n",
    "average_stars_per_language = {\n",
    "    language: stats['stars'] / stats['repos']\n",
    "    for language, stats in language_stats.items()\n",
    "    if stats['repos'] > 0\n",
    "}\n",
    "\n",
    "# Find the language with the highest average stars\n",
    "if average_stars_per_language:\n",
    "    most_popular_language = max(average_stars_per_language, key=average_stars_per_language.get)\n",
    "    print(most_popular_language)\n",
    "else:\n",
    "    print(\"No language data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Let's define leader_strength as followers / (1 + following). Who are the top 5 in terms of leader_strength? List their login in order, comma-separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dabeaz,sstephenson,khan4019,adashofdata,djspiewak\n"
     ]
    }
   ],
   "source": [
    "# Define a list to store users and their leader strength\n",
    "leader_strengths = []\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\users.csv'\n",
    "\n",
    "# Read the CSV file with UTF-8 encoding\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        # Get followers and following counts\n",
    "        followers = int(row.get('followers', 0).strip())\n",
    "        following = int(row.get('following', 0).strip())\n",
    "        \n",
    "        # Calculate leader strength\n",
    "        leader_strength = followers / (1 + following)\n",
    "        \n",
    "        # Store the user's login and their leader strength\n",
    "        leader_strengths.append((row.get('login', ''), leader_strength))\n",
    "\n",
    "# Sort users by leader strength in descending order\n",
    "leader_strengths.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the top 5 users\n",
    "top_5_leaders = [login for login, strength in leader_strengths[:5]]\n",
    "\n",
    "# Print the result as a comma-separated list\n",
    "print(','.join(top_5_leaders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What is the correlation between the number of followers and the number of public repositories among users in Chicago?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.076\n"
     ]
    }
   ],
   "source": [
    "followers = []\n",
    "public_repos = []\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\users.csv'\n",
    "\n",
    "# Open the users.csv file and read data\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        # Filter for users in Delhi\n",
    "        location = row.get('location', '').strip().lower()\n",
    "        if \"chicago\" in location:\n",
    "            # Get followers and public repositories values\n",
    "            try:\n",
    "                followers_count = int(row['followers'])\n",
    "                public_repos_count = int(row['public_repos'])\n",
    "                \n",
    "                # Append the valid values to the lists\n",
    "                followers.append(followers_count)\n",
    "                public_repos.append(public_repos_count)\n",
    "            except ValueError:\n",
    "                # Skip rows with invalid numerical values\n",
    "                continue\n",
    "\n",
    "# Ensure there is data to compute correlation\n",
    "if len(followers) > 1 and len(public_repos) > 1:\n",
    "    # Compute Pearson correlation coefficient\n",
    "    correlation_matrix = np.corrcoef(followers, public_repos)\n",
    "    correlation = correlation_matrix[0, 1]\n",
    "    # Output correlation rounded to 3 decimal places\n",
    "    print(f\"{correlation:.3f}\")\n",
    "else:\n",
    "    print(\"Insufficient data for correlation calculation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Does creating more repos help users get more followers? Using regression, estimate how many additional followers a user gets per additional public repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.610\n"
     ]
    }
   ],
   "source": [
    "followers = []\n",
    "public_repos = []\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\users.csv'\n",
    "\n",
    "# Open the users.csv file and read data\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        # Filter for users in Delhi\n",
    "        location = row.get('location', '').strip().lower()\n",
    "        if \"chicago\" in location:\n",
    "            # Get followers and public repositories values\n",
    "            try:\n",
    "                followers_count = int(row['followers'])\n",
    "                public_repos_count = int(row['public_repos'])\n",
    "                \n",
    "                # Append the valid values to the lists\n",
    "                followers.append(followers_count)\n",
    "                public_repos.append(public_repos_count)\n",
    "            except ValueError:\n",
    "                # Skip rows with invalid numerical values\n",
    "                continue\n",
    "\n",
    "# Ensure there is data for regression\n",
    "if len(followers) > 1 and len(public_repos) > 1:\n",
    "    # Perform linear regression: followers ~ public_repos\n",
    "    slope, intercept = np.polyfit(public_repos, followers, 1)\n",
    "    \n",
    "    # Output the slope rounded to 3 decimal places\n",
    "    print(f\"{slope:.3f}\")\n",
    "else:\n",
    "    print(\"Insufficient data for regression.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Do people typically enable projects and wikis together? What is the correlation between a repo having projects enabled and having wiki enabled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient: 0.287\n",
      "\n",
      "Additional Statistics:\n",
      "total_repos: 35447\n",
      "projects_enabled: 34712\n",
      "wiki_enabled: 30094\n",
      "both_enabled: 29989\n",
      "neither_enabled: 630\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\repositories.csv'\n",
    "\n",
    "def analyze_repo_features(csv_file):\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    if df['has_projects'].dtype == 'object':\n",
    "        df['has_projects'] = df['has_projects'].map({'true': True, 'false': False})\n",
    "    if df['has_wiki'].dtype == 'object':\n",
    "        df['has_wiki'] = df['has_wiki'].map({'true': True, 'false': False})\n",
    "    \n",
    "    correlation = df['has_projects'].corr(df['has_wiki'])\n",
    "    \n",
    "    stats = {\n",
    "        'total_repos': len(df),\n",
    "        'projects_enabled': df['has_projects'].sum(),\n",
    "        'wiki_enabled': df['has_wiki'].sum(),\n",
    "        'both_enabled': ((df['has_projects']) & (df['has_wiki'])).sum(),\n",
    "        'neither_enabled': ((~df['has_projects']) & (~df['has_wiki'])).sum()\n",
    "    }\n",
    "    \n",
    "    return round(correlation, 3), stats\n",
    "\n",
    "correlation, stats = analyze_repo_features(path)\n",
    "print(f\"Correlation coefficient: {correlation}\")\n",
    "print(\"\\nAdditional Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Do hireable users follow more people than those who are not hireable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hireable users: 97\n",
      "Number of non-hireable users: 285\n",
      "Average following for hireable users: 212.649\n",
      "Average following for non-hireable users: 103.772\n",
      "\n",
      "Difference in average following: 108.878\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\users.csv'\n",
    "\n",
    "def analyze_following_difference(users_csv_path=path):\n",
    "    # Read the data\n",
    "    df = pd.read_csv(users_csv_path)\n",
    "    \n",
    "    # Calculate average following for hireable users\n",
    "    hireable_following = df[df['hireable'] == True]['following'].mean()\n",
    "    \n",
    "    # Calculate average following for non-hireable users\n",
    "    non_hireable_following = df[df['hireable'] != True]['following'].mean()\n",
    "    \n",
    "    # Calculate the difference rounded to 3 decimal places\n",
    "    difference = round(hireable_following - non_hireable_following, 3)\n",
    "    \n",
    "    # Print debug information\n",
    "    print(f\"Number of hireable users: {len(df[df['hireable'] == True])}\")\n",
    "    print(f\"Number of non-hireable users: {len(df[df['hireable'] != True])}\")\n",
    "    print(f\"Average following for hireable users: {hireable_following:.3f}\")\n",
    "    print(f\"Average following for non-hireable users: {non_hireable_following:.3f}\")\n",
    "    \n",
    "    return difference\n",
    "\n",
    "# Calculate the difference\n",
    "result = analyze_following_difference()\n",
    "print(f\"\\nDifference in average following: {result:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Some developers write long bios. Does that help them get more followers? What's the impact of the length of their bio (in Unicode words, split by whitespace) with followers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Overview:\n",
      "         login              name                     company     location  \\\n",
      "0     cassidoo  Cassidy Williams                      GITHUB  Chicago, IL   \n",
      "1     felangel     Felix Angelov               SHOREBIRDTECH      Chicago   \n",
      "2       dabeaz     David Beazley                 DABEAZ, LLC      Chicago   \n",
      "3  sstephenson    Sam Stephenson                         NaN      Chicago   \n",
      "4  mattgodbolt      Matt Godbolt  AQUATIC CAPITAL MANAGEMENT  Chicago, IL   \n",
      "\n",
      "                  email  hireable  \\\n",
      "0                   NaN     False   \n",
      "1  felangelov@gmail.com     False   \n",
      "2       dave@dabeaz.com     False   \n",
      "3          sam@sls.name     False   \n",
      "4      matt@godbolt.org     False   \n",
      "\n",
      "                                                 bio  public_repos  followers  \\\n",
      "0            Making memes and dreams... and software           165      13382   \n",
      "1  software engineer by day, software engineer by...           125       8676   \n",
      "2  Author of the Python Essential Reference (Addi...            34       5181   \n",
      "3                                                NaN            24       3761   \n",
      "4  Compiler Explorer and jsbeeb creator, ex-Googl...            84       3397   \n",
      "\n",
      "   following            created_at  \n",
      "0        102  2012-02-20T16:36:23Z  \n",
      "1         67  2014-09-22T02:35:58Z  \n",
      "2          0  2010-08-01T15:22:48Z  \n",
      "3          0  2008-03-08T22:17:24Z  \n",
      "4         97  2011-02-23T13:46:48Z  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 380 entries, 0 to 379\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   login         380 non-null    object\n",
      " 1   name          374 non-null    object\n",
      " 2   company       221 non-null    object\n",
      " 3   location      380 non-null    object\n",
      " 4   email         186 non-null    object\n",
      " 5   hireable      380 non-null    bool  \n",
      " 6   bio           252 non-null    object\n",
      " 7   public_repos  380 non-null    int64 \n",
      " 8   followers     380 non-null    int64 \n",
      " 9   following     380 non-null    int64 \n",
      " 10  created_at    380 non-null    object\n",
      "dtypes: bool(1), int64(3), object(7)\n",
      "memory usage: 30.2+ KB\n",
      "None\n",
      "\n",
      "Regression slope of followers on bio word count: 3.099\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "csv_file = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\users.csv'  # Ensure this path is correct\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Check the first few rows and the data types of the DataFrame\n",
    "print(\"DataFrame Overview:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Filter out users without bios\n",
    "df = df[df['bio'].notnull()]\n",
    "\n",
    "# Calculate the length of each bio in words\n",
    "df['bio_word_count'] = df['bio'].str.split().str.len()\n",
    "\n",
    "# Prepare the independent variable (X) and dependent variable (y)\n",
    "X = df['bio_word_count']\n",
    "y = df['followers']  # Adjust the column name as per your dataset\n",
    "\n",
    "# Add a constant to the independent variable (for the intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the slope (coefficient of the bio_word_count)\n",
    "slope = model.params['bio_word_count']\n",
    "\n",
    "# Print the regression slope rounded to three decimal places\n",
    "print(f\"\\nRegression slope of followers on bio word count: {slope:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Who created the most repositories on weekends (UTC)? List the top 5 users' login in order, comma-separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marwahaha,eddelbuettel,sabre1041,erichilarysmithsr,yyolk\n"
     ]
    }
   ],
   "source": [
    "# Counter to store the number of repositories created by each user on weekends\n",
    "weekend_repo_counts = Counter()\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\repositories.csv'\n",
    "\n",
    "# Open the repositories.csv file and read data\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        created_at = row.get('created_at', '')\n",
    "        if created_at:\n",
    "            # Convert created_at string to a datetime object\n",
    "            created_date = datetime.fromisoformat(created_at[:-1])  # Remove 'Z' and convert\n",
    "            \n",
    "            # Check if the day is Saturday (5) or Sunday (6)\n",
    "            if created_date.weekday() in [5, 6]:\n",
    "                user_login = row['login']\n",
    "                weekend_repo_counts[user_login] += 1  # Increment the count for the user\n",
    "\n",
    "# Get the top 5 users who created the most repositories on weekends\n",
    "top_users = weekend_repo_counts.most_common(5)\n",
    "\n",
    "# Extract the logins of the top users\n",
    "top_logins = [user[0] for user in top_users]\n",
    "\n",
    "# Output the top users' logins as a comma-separated string\n",
    "print(','.join(top_logins))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Do people who are hireable share their email addresses more often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 382\n",
      "Hireable users with email: 53/97\n",
      "Non-hireable users with email: 133/285\n",
      "Hireable fraction: 0.546\n",
      "Non-hireable fraction: 0.467\n",
      "\n",
      "Final result: 0.080\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\users.csv'\n",
    "\n",
    "def analyze_email_sharing(users_csv_path=path):\n",
    "    # Read the complete CSV file\n",
    "    df = pd.read_csv(users_csv_path)\n",
    "    \n",
    "    # Convert email column to boolean (True if email exists, False if NaN or empty)\n",
    "    df['has_email'] = df['email'].notna() & (df['email'] != '')\n",
    "    \n",
    "    # Calculate for hireable users\n",
    "    hireable_mask = df['hireable'] == True\n",
    "    if hireable_mask.any():\n",
    "        hireable_email_fraction = df[hireable_mask]['has_email'].mean()\n",
    "    else:\n",
    "        hireable_email_fraction = 0\n",
    "        \n",
    "    # Calculate for non-hireable users\n",
    "    non_hireable_mask = df['hireable'] != True\n",
    "    if non_hireable_mask.any():\n",
    "        non_hireable_email_fraction = df[non_hireable_mask]['has_email'].mean()\n",
    "    else:\n",
    "        non_hireable_email_fraction = 0\n",
    "    \n",
    "    # Calculate difference and round to 3 decimal places\n",
    "    difference = round(hireable_email_fraction - non_hireable_email_fraction, 3)\n",
    "    \n",
    "    # Print debug information\n",
    "    print(f\"Total users: {len(df)}\")\n",
    "    print(f\"Hireable users with email: {df[hireable_mask]['has_email'].sum()}/{hireable_mask.sum()}\")\n",
    "    print(f\"Non-hireable users with email: {df[non_hireable_mask]['has_email'].sum()}/{non_hireable_mask.sum()}\")\n",
    "    print(f\"Hireable fraction: {hireable_email_fraction:.3f}\")\n",
    "    print(f\"Non-hireable fraction: {non_hireable_email_fraction:.3f}\")\n",
    "    \n",
    "    return difference\n",
    "\n",
    "# Read and analyze the complete dataset\n",
    "result = analyze_email_sharing()\n",
    "print(f\"\\nFinal result: {result:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Let's assume that the last word in a user's name is their surname (ignore missing names, trim and split by whitespace.) What's the most common surname? (If there's a tie, list them all, comma-separated, alphabetically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smith: 3\n"
     ]
    }
   ],
   "source": [
    "# Counter to store surname frequencies\n",
    "surname_counter = Counter()\n",
    "path = r'D:\\Sakthi_the_mass\\IITM\\TDS\\Project1\\pro1 (1)\\users.csv'\n",
    "\n",
    "# Open the users.csv file and read data\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        name = row.get('name', '').strip()\n",
    "        if name:  # Ignore missing names\n",
    "            # Split the name by whitespace and get the last word as the surname\n",
    "            surname = name.split()[-1]\n",
    "            surname_counter[surname] += 1\n",
    "\n",
    "# Find the maximum frequency of surnames\n",
    "if surname_counter:\n",
    "    max_count = max(surname_counter.values())\n",
    "    # Get all surnames with the maximum frequency\n",
    "    most_common_surnames = [surname for surname, count in surname_counter.items() if count == max_count]\n",
    "    # Sort surnames alphabetically\n",
    "    most_common_surnames.sort()\n",
    "    # Output the result\n",
    "    print(f\"{', '.join(most_common_surnames)}: {max_count}\")\n",
    "else:\n",
    "    print(\"No names found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
